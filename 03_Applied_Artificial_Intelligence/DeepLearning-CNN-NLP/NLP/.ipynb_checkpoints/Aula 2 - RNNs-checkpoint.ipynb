{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já sabemos fazer o processamento inicial no texto e construir um classificador, vamos explorar as arquiteturas que permitam processar a sequência de texto mais efetivamente.\n",
    "[GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)\n",
    "[LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n",
    "\n",
    "Como estes algoritmos são capazes de processar sequências de caracteres, podemos considerar tarefas mais desafiadoras.\n",
    "\n",
    "Considere o problema de **Gerar Texto**.\n",
    "\n",
    "Na aula passada consideramos a tarefa de classificar o \"sentimento\" da sentenca. Agora vamos resolver um problema mais desafiador. \n",
    "\n",
    "Nesta aula vamos modelar o estilo de \"William Shakespeare\", treinando um modelo para que complete poemas \"como Shakespeare os escreveria\".\n",
    "\n",
    "Basicamente, o problema consiste em prever a próxima palavra dado o restante da frase, por exemplo:\n",
    "\n",
    "**x** *= \"That thereby beauty's rose might never\"*, **y** *= \"die\"*\n",
    "\n",
    "\n",
    "**x** *= \"Or who is he so fond will be the\"*, **y** *= \"tomb\"*\n",
    "\n",
    "Para tanto, preparamos um dataset com exemplos de sonetos escritos por Shakespeare:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from fairest creatures we desire increase,', \"that thereby beauty's rose might never die,\", 'but as the riper should by time decease,', 'his tender heir might bear his memory:', 'but thou, contracted to thine own bright eyes,']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "data = open('./data/text_generation/sonnets.txt').read()\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "print(corpus[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como de costume, precisamos modelar esse problema de maneira que ele seja tratável com uma rede neural.\n",
    "\n",
    "Agora já sabemos utilizar a classe [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) para codificar strings, porém no problema anterior tínhamos que fazer uma classificacão binária de um texto de tamanho máximo constante.\n",
    "\n",
    "Agora, o modelo deve responder com uma palavra, como podemos modificar nossa rede neural para resolver este problema?\n",
    "\n",
    "Antes de modificar a rede neural, vamos pensar como transformaremos o texto bruto no dataset para treinamento do modelo.\n",
    "\n",
    "Uma forma é se aproveitar da funcão [pad_sequence](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) com *padding='pre'* para que normalizemos o tamanho da string de forma que a \"última palavra\" (isto é, a palavra a ser predita pelo modelo) fique na última posicão e seja fácil de se extrair.\n",
    "\n",
    "por exemplo:\n",
    "\n",
    "\n",
    "`\n",
    "\"from fairest creatures we desire increase\" -> (Tokenizer) -> \n",
    "[1, 2, 3, 4, 5, 6] -> (padding) -> [0, 0, 1, 2, 3, 4, 5, 6]`\n",
    "\n",
    "Assim, *y* é facilmente acessível no índice `sentenca[-1]`.\n",
    "\n",
    "Portanto, o primeiro passo é utilizar o tokenizer para que o vocabulário seja definido:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[35, 418, 878, 167, 214, 518],\n",
       " [9, 879, 135, 352, 103, 157, 200],\n",
       " [17, 23, 3, 880, 62, 31, 49, 635],\n",
       " [26, 312, 636, 103, 201, 26, 279],\n",
       " [17, 11, 881, 4, 63, 86, 215, 54]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_vocab_size = 1000\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size, lower=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "corpus_seqs = tokenizer.texts_to_sequences(corpus)\n",
    "corpus_seqs[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é organizar nossa base de treinamento. \n",
    "\n",
    "Como queremos que o modelo seja capaz de prever a próxima palavra em qualquer ponto da frase, vamos considerar todas as subfrases possíveis de se formar com cada linha de soneto.\n",
    "\n",
    "Por exemplo, para a frase `\"from fairest creatures we desire increase\"` as seguintes subfrases serão geradas\n",
    "\n",
    "`\n",
    "\"from fairest\"\n",
    "\"from fairest creatures\"\n",
    "\"from fairest creatures we\"\n",
    "\"from fairest creatures we desire\"\n",
    "\"from fairest creatures we desire increase\"\n",
    "`\n",
    "\n",
    "Ou, em sua versão codificada:\n",
    "\n",
    "`\n",
    "[35, 418]\n",
    "[35, 418, 878]\n",
    "[35, 418, 878, 167]\n",
    "[35, 418, 878, 167, 214]\n",
    "[35, 418, 878, 167, 214, 518]\n",
    "`\n",
    "\n",
    "Codifique uma funcao `process_corpus(seqs)` que vai transformar o corpus_seqs definido na célula acima criando as subfrases como descrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35, 418], [35, 418, 878], [35, 418, 878, 167], [35, 418, 878, 167, 214], [35, 418, 878, 167, 214, 518], [9, 879], [9, 879, 135], [9, 879, 135, 352], [9, 879, 135, 352, 103], [9, 879, 135, 352, 103, 157]]\n"
     ]
    }
   ],
   "source": [
    "def process_corpus(seqs):\n",
    "    res_seqs = []\n",
    "    for seq in seqs:\n",
    "        if len(seq) > 1:\n",
    "            for i in range(1, len(seq)):\n",
    "                res_seqs.append(seq[0:i+1])\n",
    "    return res_seqs\n",
    "\n",
    "proc_corpus = process_corpus(corpus_seqs)\n",
    "print(proc_corpus[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos fazer o processamento final das sentencas com [padding](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences).\n",
    "\n",
    "\n",
    "O faremos de modo que a \"palavra a ser predita\" fique no último índice, facilitando o processamento posterior quando precisarmos separar a base em \"x\" e \"y\".\n",
    "\n",
    "Note que aqui também devemos determinar o \"tamanho máximo da frase\", que efetivamente vai determinar até quantas palavras no passado o modelo vai olhar para definir a próxima palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0  35 418]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0  35 418 878]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0  35 418 878 167]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0  35 418 878 167 214]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0  35 418 878 167 214 518]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 30\n",
    "\n",
    "\n",
    "padded_dataset = pad_sequences(proc_corpus, maxlen=max_len + 1, padding='pre', truncating='pre')\n",
    "print(padded_dataset[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos os dados organizados de uma maneira mais palatável para uma rede neural.\n",
    "\n",
    "Diferentemente da rede construída para a tarefa de classificacão de sentimentos, aqui nossa rede neural precisa ter `max_vocab_size` saídas, que efetivamente significa que a saída da rede vai ser uma probabilidade de a próxima palavra ser cada uma das possiblidades em nosso vocábulo.\n",
    "\n",
    "Para o treinamento, é mais indicado que codifiquemos a palavra a ser prevista com um one-hot encoding, assim a saída da rede vai ser uma probabilidade para cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0  35]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0  35 418]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np\n",
    "\n",
    "X = np.array(padded_dataset[:,:-1])\n",
    "y = padded_dataset[:,-1]\n",
    "y = ku.to_categorical(y, num_classes = max_vocab_size)\n",
    "\n",
    "\n",
    "print(X[0:2])\n",
    "print(y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim, o processamento do texto está terminado e podemos treinar nossa rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               25500     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              501000    \n",
      "=================================================================\n",
      "Total params: 737,100\n",
      "Trainable params: 737,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Dropout, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(100, return_sequences = True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(max_vocab_size/2, activation='relu'))\n",
    "model.add(Dense(max_vocab_size, activation='softmax'))\n",
    "# Pick an optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15462 samples\n",
      "Epoch 1/100\n",
      "15462/15462 [==============================] - 13s 821us/sample - loss: 5.5098 - accuracy: 0.1567\n",
      "Epoch 2/100\n",
      "15462/15462 [==============================] - 11s 713us/sample - loss: 5.3396 - accuracy: 0.1572\n",
      "Epoch 3/100\n",
      "15462/15462 [==============================] - 11s 713us/sample - loss: 5.2421 - accuracy: 0.1572\n",
      "Epoch 4/100\n",
      "15462/15462 [==============================] - 11s 716us/sample - loss: 5.1640 - accuracy: 0.1571\n",
      "Epoch 5/100\n",
      "15462/15462 [==============================] - 11s 717us/sample - loss: 5.0883 - accuracy: 0.1588\n",
      "Epoch 6/100\n",
      "15462/15462 [==============================] - 12s 760us/sample - loss: 5.0068 - accuracy: 0.1616\n",
      "Epoch 7/100\n",
      "15462/15462 [==============================] - 11s 702us/sample - loss: 4.9250 - accuracy: 0.1639\n",
      "Epoch 8/100\n",
      "15462/15462 [==============================] - 11s 734us/sample - loss: 4.8482 - accuracy: 0.1647\n",
      "Epoch 9/100\n",
      "15462/15462 [==============================] - 11s 723us/sample - loss: 4.7769 - accuracy: 0.1636\n",
      "Epoch 10/100\n",
      "15462/15462 [==============================] - 11s 730us/sample - loss: 4.7089 - accuracy: 0.1694\n",
      "Epoch 11/100\n",
      "15462/15462 [==============================] - 11s 723us/sample - loss: 4.6347 - accuracy: 0.1699\n",
      "Epoch 12/100\n",
      "15462/15462 [==============================] - 11s 712us/sample - loss: 4.5603 - accuracy: 0.1739\n",
      "Epoch 13/100\n",
      "15462/15462 [==============================] - 11s 714us/sample - loss: 4.4804 - accuracy: 0.1751\n",
      "Epoch 14/100\n",
      "15462/15462 [==============================] - 11s 714us/sample - loss: 4.3989 - accuracy: 0.1764\n",
      "Epoch 15/100\n",
      "15462/15462 [==============================] - 11s 716us/sample - loss: 4.3186 - accuracy: 0.1806\n",
      "Epoch 16/100\n",
      "15462/15462 [==============================] - 11s 713us/sample - loss: 4.2337 - accuracy: 0.1814\n",
      "Epoch 17/100\n",
      "15462/15462 [==============================] - 11s 707us/sample - loss: 4.1530 - accuracy: 0.1852\n",
      "Epoch 18/100\n",
      "15462/15462 [==============================] - 11s 712us/sample - loss: 4.0701 - accuracy: 0.1870\n",
      "Epoch 19/100\n",
      "15462/15462 [==============================] - 11s 722us/sample - loss: 3.9897 - accuracy: 0.1888\n",
      "Epoch 20/100\n",
      "15462/15462 [==============================] - 11s 729us/sample - loss: 3.9071 - accuracy: 0.1940\n",
      "Epoch 21/100\n",
      "15462/15462 [==============================] - 11s 732us/sample - loss: 3.8270 - accuracy: 0.1992\n",
      "Epoch 22/100\n",
      "15462/15462 [==============================] - 11s 715us/sample - loss: 3.7475 - accuracy: 0.2016\n",
      "Epoch 23/100\n",
      "15462/15462 [==============================] - 11s 721us/sample - loss: 3.6669 - accuracy: 0.2067\n",
      "Epoch 24/100\n",
      "15462/15462 [==============================] - 11s 729us/sample - loss: 3.5874 - accuracy: 0.2139\n",
      "Epoch 25/100\n",
      "15462/15462 [==============================] - 12s 760us/sample - loss: 3.5017 - accuracy: 0.2196\n",
      "Epoch 26/100\n",
      "15462/15462 [==============================] - 11s 707us/sample - loss: 3.4262 - accuracy: 0.2247\n",
      "Epoch 27/100\n",
      "15462/15462 [==============================] - 11s 709us/sample - loss: 3.3501 - accuracy: 0.2345\n",
      "Epoch 28/100\n",
      "15462/15462 [==============================] - 11s 719us/sample - loss: 3.2690 - accuracy: 0.2447\n",
      "Epoch 29/100\n",
      "15462/15462 [==============================] - 11s 714us/sample - loss: 3.1896 - accuracy: 0.2526\n",
      "Epoch 30/100\n",
      "15462/15462 [==============================] - 11s 728us/sample - loss: 3.1139 - accuracy: 0.2635\n",
      "Epoch 31/100\n",
      "15462/15462 [==============================] - 12s 745us/sample - loss: 3.0405 - accuracy: 0.2714\n",
      "Epoch 32/100\n",
      "15462/15462 [==============================] - 11s 739us/sample - loss: 2.9653 - accuracy: 0.2899\n",
      "Epoch 33/100\n",
      "15462/15462 [==============================] - 11s 728us/sample - loss: 2.8959 - accuracy: 0.2970\n",
      "Epoch 34/100\n",
      "15462/15462 [==============================] - 12s 763us/sample - loss: 2.8229 - accuracy: 0.3112\n",
      "Epoch 35/100\n",
      "15462/15462 [==============================] - 12s 757us/sample - loss: 2.7542 - accuracy: 0.3216\n",
      "Epoch 36/100\n",
      "15462/15462 [==============================] - 11s 734us/sample - loss: 2.6922 - accuracy: 0.3302\n",
      "Epoch 37/100\n",
      "15462/15462 [==============================] - 12s 759us/sample - loss: 2.6257 - accuracy: 0.3485\n",
      "Epoch 38/100\n",
      "15462/15462 [==============================] - 12s 757us/sample - loss: 2.5590 - accuracy: 0.3586\n",
      "Epoch 39/100\n",
      "15462/15462 [==============================] - 12s 753us/sample - loss: 2.4992 - accuracy: 0.3713\n",
      "Epoch 40/100\n",
      "15462/15462 [==============================] - 11s 730us/sample - loss: 2.4391 - accuracy: 0.3831\n",
      "Epoch 41/100\n",
      "15462/15462 [==============================] - 11s 736us/sample - loss: 2.3776 - accuracy: 0.4004\n",
      "Epoch 42/100\n",
      "15462/15462 [==============================] - 11s 726us/sample - loss: 2.3261 - accuracy: 0.4083\n",
      "Epoch 43/100\n",
      "15462/15462 [==============================] - 11s 715us/sample - loss: 2.2621 - accuracy: 0.4234\n",
      "Epoch 44/100\n",
      "15462/15462 [==============================] - 12s 789us/sample - loss: 2.2226 - accuracy: 0.4316\n",
      "Epoch 45/100\n",
      "15462/15462 [==============================] - 11s 734us/sample - loss: 2.1660 - accuracy: 0.4431\n",
      "Epoch 46/100\n",
      "15462/15462 [==============================] - 11s 718us/sample - loss: 2.1065 - accuracy: 0.4563\n",
      "Epoch 47/100\n",
      "15462/15462 [==============================] - 12s 748us/sample - loss: 2.0585 - accuracy: 0.4672\n",
      "Epoch 48/100\n",
      "15462/15462 [==============================] - 11s 740us/sample - loss: 2.0134 - accuracy: 0.4789\n",
      "Epoch 49/100\n",
      "15462/15462 [==============================] - 12s 764us/sample - loss: 1.9676 - accuracy: 0.4894\n",
      "Epoch 50/100\n",
      "15462/15462 [==============================] - 12s 757us/sample - loss: 1.9130 - accuracy: 0.5037\n",
      "Epoch 51/100\n",
      "15462/15462 [==============================] - 11s 743us/sample - loss: 1.8698 - accuracy: 0.5157\n",
      "Epoch 52/100\n",
      "15462/15462 [==============================] - 12s 763us/sample - loss: 1.8271 - accuracy: 0.5263\n",
      "Epoch 53/100\n",
      "15462/15462 [==============================] - 12s 747us/sample - loss: 1.7853 - accuracy: 0.5373\n",
      "Epoch 54/100\n",
      "15462/15462 [==============================] - 11s 729us/sample - loss: 1.7493 - accuracy: 0.5417\n",
      "Epoch 55/100\n",
      "15462/15462 [==============================] - 11s 728us/sample - loss: 1.7062 - accuracy: 0.5567\n",
      "Epoch 56/100\n",
      "15462/15462 [==============================] - 11s 732us/sample - loss: 1.6720 - accuracy: 0.5622\n",
      "Epoch 57/100\n",
      "15462/15462 [==============================] - 11s 722us/sample - loss: 1.6244 - accuracy: 0.5741\n",
      "Epoch 58/100\n",
      "15462/15462 [==============================] - 11s 722us/sample - loss: 1.5998 - accuracy: 0.5803\n",
      "Epoch 59/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.5510 - accuracy: 0.5937\n",
      "Epoch 60/100\n",
      "15462/15462 [==============================] - 11s 725us/sample - loss: 1.5292 - accuracy: 0.5987\n",
      "Epoch 61/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.4923 - accuracy: 0.6103\n",
      "Epoch 62/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.4540 - accuracy: 0.6243\n",
      "Epoch 63/100\n",
      "15462/15462 [==============================] - 11s 725us/sample - loss: 1.4264 - accuracy: 0.6279\n",
      "Epoch 64/100\n",
      "15462/15462 [==============================] - 11s 718us/sample - loss: 1.4048 - accuracy: 0.6332\n",
      "Epoch 65/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.3581 - accuracy: 0.6429\n",
      "Epoch 66/100\n",
      "15462/15462 [==============================] - 11s 727us/sample - loss: 1.3401 - accuracy: 0.6495\n",
      "Epoch 67/100\n",
      "15462/15462 [==============================] - 11s 726us/sample - loss: 1.3014 - accuracy: 0.6606\n",
      "Epoch 68/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.2911 - accuracy: 0.6614\n",
      "Epoch 69/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.2694 - accuracy: 0.6665\n",
      "Epoch 70/100\n",
      "15462/15462 [==============================] - 11s 726us/sample - loss: 1.2476 - accuracy: 0.6724\n",
      "Epoch 71/100\n",
      "15462/15462 [==============================] - 11s 715us/sample - loss: 1.2050 - accuracy: 0.6830\n",
      "Epoch 72/100\n",
      "15462/15462 [==============================] - 11s 724us/sample - loss: 1.1926 - accuracy: 0.6872\n",
      "Epoch 73/100\n",
      "15462/15462 [==============================] - 11s 725us/sample - loss: 1.1604 - accuracy: 0.7002\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15462/15462 [==============================] - 11s 703us/sample - loss: 1.1372 - accuracy: 0.7044\n",
      "Epoch 75/100\n",
      "15462/15462 [==============================] - 11s 704us/sample - loss: 1.1205 - accuracy: 0.7079\n",
      "Epoch 76/100\n",
      "15462/15462 [==============================] - 11s 704us/sample - loss: 1.1144 - accuracy: 0.7078\n",
      "Epoch 77/100\n",
      "15462/15462 [==============================] - 11s 708us/sample - loss: 1.0903 - accuracy: 0.7147\n",
      "Epoch 78/100\n",
      "15462/15462 [==============================] - 11s 713us/sample - loss: 1.0654 - accuracy: 0.7234\n",
      "Epoch 79/100\n",
      "15462/15462 [==============================] - 11s 700us/sample - loss: 1.0516 - accuracy: 0.7282\n",
      "Epoch 80/100\n",
      "15462/15462 [==============================] - 11s 708us/sample - loss: 1.0248 - accuracy: 0.7342\n",
      "Epoch 81/100\n",
      "15462/15462 [==============================] - 10s 672us/sample - loss: 1.0044 - accuracy: 0.7392\n",
      "Epoch 82/100\n",
      "15462/15462 [==============================] - 10s 679us/sample - loss: 1.0028 - accuracy: 0.7387\n",
      "Epoch 83/100\n",
      "15462/15462 [==============================] - 11s 689us/sample - loss: 0.9868 - accuracy: 0.7438\n",
      "Epoch 84/100\n",
      "15462/15462 [==============================] - 11s 687us/sample - loss: 0.9716 - accuracy: 0.7493\n",
      "Epoch 85/100\n",
      "15462/15462 [==============================] - 11s 688us/sample - loss: 0.9708 - accuracy: 0.7462\n",
      "Epoch 86/100\n",
      "15462/15462 [==============================] - 11s 689us/sample - loss: 0.9511 - accuracy: 0.7521\n",
      "Epoch 87/100\n",
      "15462/15462 [==============================] - 11s 683us/sample - loss: 0.9134 - accuracy: 0.7614\n",
      "Epoch 88/100\n",
      "15462/15462 [==============================] - 11s 680us/sample - loss: 0.9067 - accuracy: 0.7650\n",
      "Epoch 89/100\n",
      "15462/15462 [==============================] - 11s 690us/sample - loss: 0.9093 - accuracy: 0.7631\n",
      "Epoch 90/100\n",
      "15462/15462 [==============================] - 11s 680us/sample - loss: 0.8910 - accuracy: 0.7681\n",
      "Epoch 91/100\n",
      "15462/15462 [==============================] - 10s 675us/sample - loss: 0.8810 - accuracy: 0.7702\n",
      "Epoch 92/100\n",
      "15462/15462 [==============================] - 10s 676us/sample - loss: 0.8573 - accuracy: 0.7764\n",
      "Epoch 93/100\n",
      "15462/15462 [==============================] - 10s 677us/sample - loss: 0.8633 - accuracy: 0.7740\n",
      "Epoch 94/100\n",
      "15462/15462 [==============================] - 10s 677us/sample - loss: 0.8808 - accuracy: 0.7690\n",
      "Epoch 95/100\n",
      "15462/15462 [==============================] - 11s 684us/sample - loss: 0.8555 - accuracy: 0.7761\n",
      "Epoch 96/100\n",
      "15462/15462 [==============================] - 11s 690us/sample - loss: 0.8146 - accuracy: 0.7897\n",
      "Epoch 97/100\n",
      "15462/15462 [==============================] - 11s 682us/sample - loss: 0.7990 - accuracy: 0.7927\n",
      "Epoch 98/100\n",
      "15462/15462 [==============================] - 10s 675us/sample - loss: 0.7952 - accuracy: 0.7938\n",
      "Epoch 99/100\n",
      "15462/15462 [==============================] - 10s 678us/sample - loss: 0.7942 - accuracy: 0.7943\n",
      "Epoch 100/100\n",
      "15462/15462 [==============================] - 11s 692us/sample - loss: 0.8305 - accuracy: 0.7784\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo pode agora ser utilizado para  prever as próximas palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_next_word(model, frase):\n",
    "    sequences = tokenizer.texts_to_sequences([frase])\n",
    "    padded = pad_sequences(sequences, maxlen=max_len , padding='pre', truncating='pre')\n",
    "    predicted = model.predict_classes(padded)\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    return output_word\n",
    "    \n",
    "get_next_word(model, 'please, save me in this')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclusive, podemos gerar uma sequencia maior de palavras para formar um novo soneto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please, save me in this world out by thy gentle grace another defence <OOV> brand new pride can truly pace it in and pride in thee to prove false pride <OOV> thee <OOV> heaven's of state nor eyes be <OOV> true fire a end all me nor <OOV> steel <OOV> better under thee be gone\n"
     ]
    }
   ],
   "source": [
    "generate_words = 50\n",
    "\n",
    "sentence = 'please, save me in this'\n",
    "for i in range(generate_words):\n",
    "    sentence = sentence + \" \" + get_next_word(model, sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para uma determinada entrada, o modelo sempre vai responder a mesma palavra, o que não é interessante. Modifique a funcão `get_next_word` para retornar uma palavra com probabilidade igual à especificada pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste diversas possibilidades de arquitetura, com modelos bidirecionais, LSTM e GRUs, quais deles obtém um resultado melhor?\n",
    "\n",
    "\n",
    "Após isso, tente treinar um modelo semelhante usando poemas de [Goncalves Dias](http://www.dominiopublico.gov.br/download/texto/bv000115.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
