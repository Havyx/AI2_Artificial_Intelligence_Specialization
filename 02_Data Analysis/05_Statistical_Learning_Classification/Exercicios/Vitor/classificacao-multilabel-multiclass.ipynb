{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Classificadores Lineares\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Classificadores KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Classificadores Naive Nayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Classificadores Arvores de Decisão\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, classification_report\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn import linear_model\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy.io import arff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação com Multiplas Classes\n",
    "* A resposta (y) ́e umas das multiplas classes possıveis\n",
    "\n",
    "### Usando base Iris para teste\n",
    "#### Variáveis independentes:\n",
    "\n",
    "* Largura de pétala\n",
    "* altura de pétala\n",
    "* Largura de sépala\n",
    "* altura de sépala\n",
    "\n",
    "#### Variável a ser predita:\n",
    "* Predizer: species (Nesse dataset 3 possíveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para datasets com muitas variáveis independentes é possível eliminar apenas o label usando drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "X = df.drop(['species'], axis=1)\n",
    "y = df[['species']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print( df['species'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi_class{‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’\n",
    "\n",
    "* Se a opção escolhida for \"ovr\", um problema binário é montado para cada rótulo. \n",
    "* Para \"multinomial\", a perda minimizada é o ajuste de perda multinomial em toda a distribuição de probabilidade, mesmo se houber apenas duas classes\n",
    "* \"Multinomial\" fica indisponível quando solver = 'liblinear'. \n",
    "'Auto' seleciona 'ovr' se os dados são binários ou se solver = 'liblinear' caso contrário, seleciona 'multinomial'.\n",
    "\n",
    "ref: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "* Algoritmo a ser usado na otimização.\n",
    "\n",
    "* Para conjuntos de dados pequenos, 'liblinear' é uma boa opção, enquanto 'sag' e 'saga' são mais rápidos para conjuntos grandes de dados\n",
    "\n",
    "* Apenas 'newton-cg', 'sag', 'saga' e 'lbfgs' lidam com a perda multinomial; \n",
    "\n",
    "* \"Liblinear\" é limitado a esquemas de um contra o resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd_clf = SGDClassifier(random_state=42)\n",
    "#sgd_clf = LogisticRegression(multi_class='multinomial',solver='sag')\n",
    "# 'newton-cg', 'sag', 'saga' e 'lbfgs\n",
    "sgd_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A matriz de confusão gerada para datasets com variável alvo possuindo mais de uma classe, é quadrada sendo seu tamanho igual a quantidade de classes\n",
    "\n",
    "### Para esse caso três espécies, portanto matriz quadrada 3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretação\n",
    "* As classes setosa e versicolor não tiverem erros (precision 1)\n",
    "* A classe virginica houve 5 erros (precision 0.69)\n",
    "* versicolor possui recall 0.71 => TP / TP+FN (12 / 12 + 5) => 0.7\n",
    "* nesse caso, instancias da classe virginica todos foram confundidos com versicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando múltiplas classes com KNN, Arvore e Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arvore de Decição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       0.83      1.00      0.91         5\n",
      "   virginica       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.94      0.94      0.94        15\n",
      "weighted avg       0.94      0.93      0.93        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de classificador um contra todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo de classificador aos pares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00         4\n",
      "  versicolor       1.00      1.00      1.00         5\n",
      "   virginica       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício Mnist\n",
    "* 786 colunas de características\n",
    "* coluna label identifica o número\n",
    "* crie um dataframe para representar a base mnist\n",
    "* crie um classificador de multiplas classes (usando a coluna label) como alvo\n",
    "* interprete o resultado\n",
    "* Qual valor (entre 0 a 9) o classificador teve mais sucesso em identificar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       980\n",
      "           1       0.95      0.96      0.95      1135\n",
      "           2       0.86      0.85      0.86      1032\n",
      "           3       0.83      0.84      0.84      1010\n",
      "           4       0.88      0.87      0.87       982\n",
      "           5       0.83      0.83      0.83       892\n",
      "           6       0.90      0.88      0.89       958\n",
      "           7       0.90      0.91      0.90      1028\n",
      "           8       0.83      0.81      0.82       974\n",
      "           9       0.85      0.86      0.86      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Resolva o exercicio aqui...\n",
    "df_train = pd.read_csv('mnist-in-csv/mnist_train.csv')\n",
    "df.describe()\n",
    "\n",
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']\n",
    "\n",
    "df_test = pd.read_csv('mnist-in-csv/mnist_test.csv')\n",
    "\n",
    "X_test = df_test.drop(['label'], axis=1)\n",
    "y_test = df_test['label']\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "# O classificador obteve maior sucesso em identificar o numero 1 e maior dificuldade em classificar o numero 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       980\n",
      "           1       0.94      1.00      0.97      1135\n",
      "           2       0.98      0.95      0.97      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.97      0.96      0.97       982\n",
      "           5       0.97      0.97      0.97       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.99      0.93      0.96       974\n",
      "           9       0.96      0.95      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=8, n_jobs=12)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.0000</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.453933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>0.088867</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.889270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.042472</td>\n",
       "      <td>3.956189</td>\n",
       "      <td>2.839845</td>\n",
       "      <td>1.686770</td>\n",
       "      <td>1.678283</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label      1x1      1x2      1x3      1x4      1x5      1x6  \\\n",
       "count  60000.000000  60000.0  60000.0  60000.0  60000.0  60000.0  60000.0   \n",
       "mean       4.453933      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.889270      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           1x7      1x8      1x9  ...         28x19         28x20  \\\n",
       "count  60000.0  60000.0  60000.0  ...  60000.000000  60000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.200433      0.088867   \n",
       "std        0.0      0.0      0.0  ...      6.042472      3.956189   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "              28x21         28x22         28x23       28x24    28x25    28x26  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.0000  60000.0  60000.0   \n",
       "mean       0.045633      0.019283      0.015117      0.0020      0.0      0.0   \n",
       "std        2.839845      1.686770      1.678283      0.3466      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0000      0.0      0.0   \n",
       "max      253.000000    253.000000    254.000000     62.0000      0.0      0.0   \n",
       "\n",
       "         28x27    28x28  \n",
       "count  60000.0  60000.0  \n",
       "mean       0.0      0.0  \n",
       "std        0.0      0.0  \n",
       "min        0.0      0.0  \n",
       "25%        0.0      0.0  \n",
       "50%        0.0      0.0  \n",
       "75%        0.0      0.0  \n",
       "max        0.0      0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mnist-in-csv/mnist_train.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação entre variável indepentes X e variáveis alvo Y \n",
    "* Mais de uma classe possível para cada instância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  método scipy.io.arff.loadarff \n",
    "* Método para leitura de arquivos no formato Attribute-Relation File Format (ARFF)\n",
    "* Fonte de bases de dados multilabel no formato arff : https://github.com/tsoumakas/mulan/tree/master/data/multi-label\n",
    "* (yeast): base de dados para estudos de proteínas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yeast-train.arff.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9313b1a9eedc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yeast-train.arff.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/amb1/lib/python3.7/site-packages/scipy/io/arff/arffread.py\u001b[0m in \u001b[0;36mloadarff\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loadarff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mofile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yeast-train.arff.txt'"
     ]
    }
   ],
   "source": [
    "data, meta = scipy.io.arff.loadarff('yeast-train.arff.txt')\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação de dados\n",
    "* Codificação de variáveis categóricas\n",
    "* Separação em Treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14'], axis=1)\n",
    "Y = df[['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y['class1'] = le.fit_transform(Y['Class1'])\n",
    "Y['class2'] = le.fit_transform(Y['Class2'])\n",
    "Y['class3'] = le.fit_transform(Y['Class3'])\n",
    "Y['class4'] = le.fit_transform(Y['Class4'])\n",
    "Y['class5'] = le.fit_transform(Y['Class5'])\n",
    "Y['class6'] = le.fit_transform(Y['Class6'])\n",
    "Y['class7'] = le.fit_transform(Y['Class7'])\n",
    "Y['class8'] = le.fit_transform(Y['Class8'])\n",
    "Y['class9'] = le.fit_transform(Y['Class9'])\n",
    "Y['class10'] = le.fit_transform(Y['Class10'])\n",
    "Y['class11'] = le.fit_transform(Y['Class11'])\n",
    "Y['class12'] = le.fit_transform(Y['Class12'])\n",
    "Y['class13'] = le.fit_transform(Y['Class13'])\n",
    "Y['class14'] = le.fit_transform(Y['Class14'])\n",
    "\n",
    "Y = Y.drop(['Class1','Class2','Class3','Class4','Class5','Class6','Class7','Class8','Class9','Class10','Class11','Class12','Class13','Class14'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando regressão logística a dados multi-classe\n",
    "* Método apresenta erro de mal-formato de Y, indicando que não aceita múltiplas classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "y_pred = sgd_clf.predict(X_train)\n",
    "print(classification_report(Y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerando apenas uma classe como variável a ser predita\n",
    "* Regressão Logística funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = Y[['class1']]\n",
    "\n",
    "sgd_clf = LogisticRegression(multi_class='multinomial',solver='lbfgs')\n",
    "#sgd_clf = LogisticRegression()\n",
    "sgd_clf.fit(X, YY)\n",
    "y_pred = sgd_clf.predict(X)\n",
    "print(classification_report(YY, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No scikit-learn alguns métodos aceitam dataset multiclasse: como o DecisionTreeClassifier por exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = DecisionTreeClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outro exemplo de método que aceita múltiplas classes por instância:\n",
    "* import sklearn.ensemble.ExtraTreesClassifier\n",
    "* import sklearn.neighbors.KNeighborsClassifier\n",
    "* import sklearn.neighbors.RadiusNeighborsClassifier\n",
    "* import sklearn.ensemble.RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = KNeighborsClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando modelos:\n",
    "\n",
    "* Micro average (média do total de verdadeiros positivos, falsos negativos e falsos positivos) para múltiplas classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício\n",
    "### Dataset de Paisagens: \n",
    "\n",
    "* 294 atributos para descrever a imagem \n",
    "* 6 colunas para predição: Beach Sunset FallFoliage Field Mountain Urban\n",
    "\n",
    "Arquivo: scene.arff\n",
    "Fonte: https://datahub.io/machine-learning/scene\n",
    "\n",
    "Faça um classificador multiclassse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>attr8</th>\n",
       "      <th>attr9</th>\n",
       "      <th>attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>attr291</th>\n",
       "      <th>attr292</th>\n",
       "      <th>attr293</th>\n",
       "      <th>attr294</th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Field</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.646467</td>\n",
       "      <td>0.666435</td>\n",
       "      <td>0.685047</td>\n",
       "      <td>0.699053</td>\n",
       "      <td>0.652746</td>\n",
       "      <td>0.407864</td>\n",
       "      <td>0.150309</td>\n",
       "      <td>0.535193</td>\n",
       "      <td>0.555689</td>\n",
       "      <td>0.580782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157332</td>\n",
       "      <td>0.247298</td>\n",
       "      <td>0.014025</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.770156</td>\n",
       "      <td>0.767255</td>\n",
       "      <td>0.761053</td>\n",
       "      <td>0.745630</td>\n",
       "      <td>0.742231</td>\n",
       "      <td>0.688086</td>\n",
       "      <td>0.708416</td>\n",
       "      <td>0.757351</td>\n",
       "      <td>0.760633</td>\n",
       "      <td>0.740314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251454</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.082672</td>\n",
       "      <td>0.036320</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.793984</td>\n",
       "      <td>0.772096</td>\n",
       "      <td>0.761820</td>\n",
       "      <td>0.762213</td>\n",
       "      <td>0.740569</td>\n",
       "      <td>0.734361</td>\n",
       "      <td>0.722677</td>\n",
       "      <td>0.849128</td>\n",
       "      <td>0.839607</td>\n",
       "      <td>0.812746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017166</td>\n",
       "      <td>0.051125</td>\n",
       "      <td>0.112506</td>\n",
       "      <td>0.083924</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.938563</td>\n",
       "      <td>0.949260</td>\n",
       "      <td>0.955621</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.869619</td>\n",
       "      <td>0.696925</td>\n",
       "      <td>0.953460</td>\n",
       "      <td>0.959631</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.031290</td>\n",
       "      <td>0.049780</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.512130</td>\n",
       "      <td>0.524684</td>\n",
       "      <td>0.520020</td>\n",
       "      <td>0.504467</td>\n",
       "      <td>0.471209</td>\n",
       "      <td>0.417654</td>\n",
       "      <td>0.364292</td>\n",
       "      <td>0.562266</td>\n",
       "      <td>0.588592</td>\n",
       "      <td>0.584449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198151</td>\n",
       "      <td>0.238796</td>\n",
       "      <td>0.164270</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2402</td>\n",
       "      <td>0.875782</td>\n",
       "      <td>0.901653</td>\n",
       "      <td>0.926227</td>\n",
       "      <td>0.721366</td>\n",
       "      <td>0.795826</td>\n",
       "      <td>0.867642</td>\n",
       "      <td>0.794125</td>\n",
       "      <td>0.899067</td>\n",
       "      <td>0.908963</td>\n",
       "      <td>0.895336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215147</td>\n",
       "      <td>0.279607</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2403</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>0.669877</td>\n",
       "      <td>0.692338</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>0.727374</td>\n",
       "      <td>0.750354</td>\n",
       "      <td>0.684372</td>\n",
       "      <td>0.718770</td>\n",
       "      <td>0.719916</td>\n",
       "      <td>0.730645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217201</td>\n",
       "      <td>0.199491</td>\n",
       "      <td>0.048747</td>\n",
       "      <td>0.041638</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2404</td>\n",
       "      <td>0.952281</td>\n",
       "      <td>0.944987</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.836604</td>\n",
       "      <td>0.875916</td>\n",
       "      <td>0.957034</td>\n",
       "      <td>0.953938</td>\n",
       "      <td>0.967956</td>\n",
       "      <td>0.819636</td>\n",
       "      <td>0.707311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028002</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.019734</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2405</td>\n",
       "      <td>0.883990</td>\n",
       "      <td>0.899004</td>\n",
       "      <td>0.901019</td>\n",
       "      <td>0.904298</td>\n",
       "      <td>0.846402</td>\n",
       "      <td>0.858145</td>\n",
       "      <td>0.851362</td>\n",
       "      <td>0.852472</td>\n",
       "      <td>0.876665</td>\n",
       "      <td>0.908187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239041</td>\n",
       "      <td>0.256158</td>\n",
       "      <td>0.226332</td>\n",
       "      <td>0.223070</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2406</td>\n",
       "      <td>0.974915</td>\n",
       "      <td>0.866425</td>\n",
       "      <td>0.818144</td>\n",
       "      <td>0.936140</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.935087</td>\n",
       "      <td>0.930597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.806074</td>\n",
       "      <td>0.717955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073742</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.025059</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2407 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
       "0     0.646467  0.666435  0.685047  0.699053  0.652746  0.407864  0.150309   \n",
       "1     0.770156  0.767255  0.761053  0.745630  0.742231  0.688086  0.708416   \n",
       "2     0.793984  0.772096  0.761820  0.762213  0.740569  0.734361  0.722677   \n",
       "3     0.938563  0.949260  0.955621  0.966743  0.968649  0.869619  0.696925   \n",
       "4     0.512130  0.524684  0.520020  0.504467  0.471209  0.417654  0.364292   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2402  0.875782  0.901653  0.926227  0.721366  0.795826  0.867642  0.794125   \n",
       "2403  0.657706  0.669877  0.692338  0.713920  0.727374  0.750354  0.684372   \n",
       "2404  0.952281  0.944987  0.905556  0.836604  0.875916  0.957034  0.953938   \n",
       "2405  0.883990  0.899004  0.901019  0.904298  0.846402  0.858145  0.851362   \n",
       "2406  0.974915  0.866425  0.818144  0.936140  0.938583  0.935087  0.930597   \n",
       "\n",
       "         attr8     attr9    attr10  ...   attr291   attr292   attr293  \\\n",
       "0     0.535193  0.555689  0.580782  ...  0.157332  0.247298  0.014025   \n",
       "1     0.757351  0.760633  0.740314  ...  0.251454  0.137833  0.082672   \n",
       "2     0.849128  0.839607  0.812746  ...  0.017166  0.051125  0.112506   \n",
       "3     0.953460  0.959631  0.966320  ...  0.019267  0.031290  0.049780   \n",
       "4     0.562266  0.588592  0.584449  ...  0.198151  0.238796  0.164270   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2402  0.899067  0.908963  0.895336  ...  0.215147  0.279607  0.254413   \n",
       "2403  0.718770  0.719916  0.730645  ...  0.217201  0.199491  0.048747   \n",
       "2404  0.967956  0.819636  0.707311  ...  0.028002  0.031900  0.017547   \n",
       "2405  0.852472  0.876665  0.908187  ...  0.239041  0.256158  0.226332   \n",
       "2406  1.000000  0.806074  0.717955  ...  0.073742  0.005131  0.025059   \n",
       "\n",
       "       attr294  Beach  Sunset  FallFoliage  Field  Mountain  Urban  \n",
       "0     0.029709   b'1'    b'0'         b'0'   b'0'      b'1'   b'0'  \n",
       "1     0.036320   b'1'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2     0.083924   b'1'    b'0'         b'0'   b'0'      b'0'   b'0'  \n",
       "3     0.090959   b'1'    b'0'         b'0'   b'0'      b'0'   b'0'  \n",
       "4     0.184290   b'1'    b'0'         b'0'   b'0'      b'0'   b'0'  \n",
       "...        ...    ...     ...          ...    ...       ...    ...  \n",
       "2402  0.134350   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2403  0.041638   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2404  0.019734   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2405  0.223070   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "2406  0.004033   b'0'    b'0'         b'0'   b'0'      b'0'   b'1'  \n",
       "\n",
       "[2407 rows x 300 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, meta = scipy.io.arff.loadarff('scene_arff.arff')\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Beach','Sunset','FallFoliage','Field','Mountain','Urban'], axis=1)\n",
    "Y = df[['Beach','Sunset','FallFoliage','Field', 'Mountain','Urban']]\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y['Beach'] = le.fit_transform(Y['Beach'])\n",
    "Y['Sunset'] = le.fit_transform(Y['Sunset'])\n",
    "Y['FallFoliage'] = le.fit_transform(Y['FallFoliage'])\n",
    "Y['Field'] = le.fit_transform(Y['Field'])\n",
    "Y['Mountain'] = le.fit_transform(Y['Mountain'])\n",
    "Y['Urban'] = le.fit_transform(Y['Urban'])\n",
    "\n",
    "#Y = Y.drop(['Beach','Sunset','FallFoliage','Mountain','Urban'], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "      <th>attr3</th>\n",
       "      <th>attr4</th>\n",
       "      <th>attr5</th>\n",
       "      <th>attr6</th>\n",
       "      <th>attr7</th>\n",
       "      <th>attr8</th>\n",
       "      <th>attr9</th>\n",
       "      <th>attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>attr285</th>\n",
       "      <th>attr286</th>\n",
       "      <th>attr287</th>\n",
       "      <th>attr288</th>\n",
       "      <th>attr289</th>\n",
       "      <th>attr290</th>\n",
       "      <th>attr291</th>\n",
       "      <th>attr292</th>\n",
       "      <th>attr293</th>\n",
       "      <th>attr294</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1689</td>\n",
       "      <td>0.463177</td>\n",
       "      <td>0.480873</td>\n",
       "      <td>0.508331</td>\n",
       "      <td>0.542606</td>\n",
       "      <td>0.549585</td>\n",
       "      <td>0.242810</td>\n",
       "      <td>0.349307</td>\n",
       "      <td>0.527351</td>\n",
       "      <td>0.545258</td>\n",
       "      <td>0.562826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377253</td>\n",
       "      <td>0.191037</td>\n",
       "      <td>0.056861</td>\n",
       "      <td>0.521932</td>\n",
       "      <td>0.318598</td>\n",
       "      <td>0.472638</td>\n",
       "      <td>0.862374</td>\n",
       "      <td>0.659360</td>\n",
       "      <td>0.268643</td>\n",
       "      <td>0.228774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>0.578401</td>\n",
       "      <td>0.666313</td>\n",
       "      <td>0.704211</td>\n",
       "      <td>0.736297</td>\n",
       "      <td>0.745189</td>\n",
       "      <td>0.725860</td>\n",
       "      <td>0.659437</td>\n",
       "      <td>0.658399</td>\n",
       "      <td>0.709895</td>\n",
       "      <td>0.741473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182193</td>\n",
       "      <td>0.168191</td>\n",
       "      <td>0.503346</td>\n",
       "      <td>0.185779</td>\n",
       "      <td>0.118632</td>\n",
       "      <td>0.080176</td>\n",
       "      <td>0.060279</td>\n",
       "      <td>0.073175</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>0.151265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1351</td>\n",
       "      <td>0.730944</td>\n",
       "      <td>0.728207</td>\n",
       "      <td>0.725545</td>\n",
       "      <td>0.725192</td>\n",
       "      <td>0.721745</td>\n",
       "      <td>0.717475</td>\n",
       "      <td>0.714194</td>\n",
       "      <td>0.742610</td>\n",
       "      <td>0.763411</td>\n",
       "      <td>0.778533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490913</td>\n",
       "      <td>0.286378</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.019734</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>0.024417</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.008662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.448059</td>\n",
       "      <td>0.499676</td>\n",
       "      <td>0.471095</td>\n",
       "      <td>0.649933</td>\n",
       "      <td>0.764011</td>\n",
       "      <td>0.724661</td>\n",
       "      <td>0.676907</td>\n",
       "      <td>0.422027</td>\n",
       "      <td>0.475449</td>\n",
       "      <td>0.471905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126569</td>\n",
       "      <td>0.150774</td>\n",
       "      <td>0.150403</td>\n",
       "      <td>0.262727</td>\n",
       "      <td>0.317911</td>\n",
       "      <td>0.339256</td>\n",
       "      <td>0.217705</td>\n",
       "      <td>0.117453</td>\n",
       "      <td>0.072698</td>\n",
       "      <td>0.146170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1317</td>\n",
       "      <td>0.617061</td>\n",
       "      <td>0.460076</td>\n",
       "      <td>0.337591</td>\n",
       "      <td>0.693253</td>\n",
       "      <td>0.663105</td>\n",
       "      <td>0.599121</td>\n",
       "      <td>0.471719</td>\n",
       "      <td>0.658140</td>\n",
       "      <td>0.572467</td>\n",
       "      <td>0.241446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085120</td>\n",
       "      <td>0.146505</td>\n",
       "      <td>0.115387</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.036469</td>\n",
       "      <td>0.039448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>0.935084</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.958368</td>\n",
       "      <td>0.951894</td>\n",
       "      <td>0.938494</td>\n",
       "      <td>0.918042</td>\n",
       "      <td>0.902955</td>\n",
       "      <td>0.955249</td>\n",
       "      <td>0.961176</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325231</td>\n",
       "      <td>0.081592</td>\n",
       "      <td>0.122748</td>\n",
       "      <td>0.106135</td>\n",
       "      <td>0.061651</td>\n",
       "      <td>0.110331</td>\n",
       "      <td>0.601508</td>\n",
       "      <td>0.527749</td>\n",
       "      <td>0.207364</td>\n",
       "      <td>0.130905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.706286</td>\n",
       "      <td>0.577826</td>\n",
       "      <td>0.594672</td>\n",
       "      <td>0.594146</td>\n",
       "      <td>0.544052</td>\n",
       "      <td>0.561741</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>0.600123</td>\n",
       "      <td>0.639842</td>\n",
       "      <td>0.663776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023413</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.019532</td>\n",
       "      <td>0.020479</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.164264</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.080567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>807</td>\n",
       "      <td>0.575684</td>\n",
       "      <td>0.779691</td>\n",
       "      <td>0.832105</td>\n",
       "      <td>0.784591</td>\n",
       "      <td>0.826575</td>\n",
       "      <td>0.878018</td>\n",
       "      <td>0.870324</td>\n",
       "      <td>0.030281</td>\n",
       "      <td>0.606201</td>\n",
       "      <td>0.846400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138981</td>\n",
       "      <td>0.099661</td>\n",
       "      <td>0.049716</td>\n",
       "      <td>0.384828</td>\n",
       "      <td>0.080523</td>\n",
       "      <td>0.272303</td>\n",
       "      <td>0.091974</td>\n",
       "      <td>0.041060</td>\n",
       "      <td>0.019354</td>\n",
       "      <td>0.033664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345</td>\n",
       "      <td>0.720750</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.920031</td>\n",
       "      <td>0.916465</td>\n",
       "      <td>0.894297</td>\n",
       "      <td>0.842296</td>\n",
       "      <td>0.726647</td>\n",
       "      <td>0.453031</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117764</td>\n",
       "      <td>0.079952</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.074445</td>\n",
       "      <td>0.124968</td>\n",
       "      <td>0.039466</td>\n",
       "      <td>0.034784</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>0.071508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>0.783138</td>\n",
       "      <td>0.864510</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.905667</td>\n",
       "      <td>0.705536</td>\n",
       "      <td>0.608948</td>\n",
       "      <td>0.570076</td>\n",
       "      <td>0.724888</td>\n",
       "      <td>0.881037</td>\n",
       "      <td>0.906987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050724</td>\n",
       "      <td>0.099776</td>\n",
       "      <td>0.075291</td>\n",
       "      <td>0.144336</td>\n",
       "      <td>0.055389</td>\n",
       "      <td>0.027587</td>\n",
       "      <td>0.049431</td>\n",
       "      <td>0.064412</td>\n",
       "      <td>0.124343</td>\n",
       "      <td>0.036019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2166 rows × 294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
       "1689  0.463177  0.480873  0.508331  0.542606  0.549585  0.242810  0.349307   \n",
       "1672  0.578401  0.666313  0.704211  0.736297  0.745189  0.725860  0.659437   \n",
       "1351  0.730944  0.728207  0.725545  0.725192  0.721745  0.717475  0.714194   \n",
       "502   0.448059  0.499676  0.471095  0.649933  0.764011  0.724661  0.676907   \n",
       "1317  0.617061  0.460076  0.337591  0.693253  0.663105  0.599121  0.471719   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "808   0.935084  0.949421  0.958368  0.951894  0.938494  0.918042  0.902955   \n",
       "132   0.706286  0.577826  0.594672  0.594146  0.544052  0.561741  0.621528   \n",
       "807   0.575684  0.779691  0.832105  0.784591  0.826575  0.878018  0.870324   \n",
       "2345  0.720750  0.575107  0.916003  0.920031  0.916465  0.894297  0.842296   \n",
       "691   0.783138  0.864510  0.896226  0.905667  0.705536  0.608948  0.570076   \n",
       "\n",
       "         attr8     attr9    attr10  ...   attr285   attr286   attr287  \\\n",
       "1689  0.527351  0.545258  0.562826  ...  0.377253  0.191037  0.056861   \n",
       "1672  0.658399  0.709895  0.741473  ...  0.182193  0.168191  0.503346   \n",
       "1351  0.742610  0.763411  0.778533  ...  0.490913  0.286378  0.174800   \n",
       "502   0.422027  0.475449  0.471905  ...  0.126569  0.150774  0.150403   \n",
       "1317  0.658140  0.572467  0.241446  ...  0.085120  0.146505  0.115387   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "808   0.955249  0.961176  0.969910  ...  0.325231  0.081592  0.122748   \n",
       "132   0.600123  0.639842  0.663776  ...  1.000000  0.023413  0.064990   \n",
       "807   0.030281  0.606201  0.846400  ...  0.138981  0.099661  0.049716   \n",
       "2345  0.726647  0.453031  0.835556  ...  0.117764  0.079952  0.016931   \n",
       "691   0.724888  0.881037  0.906987  ...  0.050724  0.099776  0.075291   \n",
       "\n",
       "       attr288   attr289   attr290   attr291   attr292   attr293   attr294  \n",
       "1689  0.521932  0.318598  0.472638  0.862374  0.659360  0.268643  0.228774  \n",
       "1672  0.185779  0.118632  0.080176  0.060279  0.073175  0.099411  0.151265  \n",
       "1351  0.019734  0.018106  0.024417  0.018410  0.014828  0.012360  0.008662  \n",
       "502   0.262727  0.317911  0.339256  0.217705  0.117453  0.072698  0.146170  \n",
       "1317  0.013312  0.015948  0.021493  0.012682  0.005499  0.036469  0.039448  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "808   0.106135  0.061651  0.110331  0.601508  0.527749  0.207364  0.130905  \n",
       "132   0.033235  0.019532  0.020479  0.001962  0.164264  0.027100  0.080567  \n",
       "807   0.384828  0.080523  0.272303  0.091974  0.041060  0.019354  0.033664  \n",
       "2345  0.074445  0.124968  0.039466  0.034784  0.009523  0.040892  0.071508  \n",
       "691   0.144336  0.055389  0.027587  0.049431  0.064412  0.124343  0.036019  \n",
       "\n",
       "[2166 rows x 294 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beach</th>\n",
       "      <th>Sunset</th>\n",
       "      <th>FallFoliage</th>\n",
       "      <th>Field</th>\n",
       "      <th>Mountain</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2166 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Beach  Sunset  FallFoliage  Field  Mountain  Urban\n",
       "1689      0       0            1      0         0      0\n",
       "1672      0       0            1      0         0      0\n",
       "1351      1       0            0      0         0      0\n",
       "502       0       0            1      0         0      0\n",
       "1317      1       0            0      0         0      0\n",
       "...     ...     ...          ...    ...       ...    ...\n",
       "808       0       0            0      1         1      0\n",
       "132       1       0            0      0         0      1\n",
       "807       0       0            0      0         1      0\n",
       "2345      0       0            0      0         0      1\n",
       "691       0       0            0      1         0      0\n",
       "\n",
       "[2166 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.68      0.58        34\n",
      "           1       0.58      0.68      0.63        31\n",
      "           2       0.70      0.57      0.63        54\n",
      "           3       0.75      0.69      0.72        48\n",
      "           4       0.50      0.51      0.51        49\n",
      "           5       0.46      0.53      0.49        40\n",
      "\n",
      "   micro avg       0.58      0.60      0.59       256\n",
      "   macro avg       0.58      0.61      0.59       256\n",
      "weighted avg       0.59      0.60      0.59       256\n",
      " samples avg       0.59      0.60      0.59       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = DecisionTreeClassifier()\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76        34\n",
      "           1       1.00      0.61      0.76        31\n",
      "           2       0.97      0.70      0.82        54\n",
      "           3       1.00      0.71      0.83        48\n",
      "           4       0.62      0.27      0.37        49\n",
      "           5       0.73      0.28      0.40        40\n",
      "\n",
      "   micro avg       0.90      0.54      0.67       256\n",
      "   macro avg       0.87      0.54      0.66       256\n",
      "weighted avg       0.87      0.54      0.65       256\n",
      " samples avg       0.56      0.54      0.54       256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=12)\n",
    "\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.50      0.63        34\n",
      "           1       0.85      0.55      0.67        31\n",
      "           2       0.91      0.54      0.67        54\n",
      "           3       1.00      0.69      0.81        48\n",
      "           4       0.65      0.35      0.45        49\n",
      "           5       0.65      0.28      0.39        40\n",
      "\n",
      "   micro avg       0.84      0.48      0.61       256\n",
      "   macro avg       0.82      0.48      0.60       256\n",
      "weighted avg       0.82      0.48      0.61       256\n",
      " samples avg       0.50      0.49      0.49       256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_jobs=12)\n",
    "\n",
    "etc.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = etc.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68        34\n",
      "           1       0.91      0.65      0.75        31\n",
      "           2       0.89      0.76      0.82        54\n",
      "           3       0.93      0.77      0.84        48\n",
      "           4       0.71      0.49      0.58        49\n",
      "           5       0.56      0.70      0.62        40\n",
      "\n",
      "   micro avg       0.78      0.66      0.72       256\n",
      "   macro avg       0.80      0.66      0.72       256\n",
      "weighted avg       0.80      0.66      0.72       256\n",
      " samples avg       0.70      0.68      0.68       256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vitorbezerra/miniconda3/envs/amb1/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = KNeighborsClassifier(n_jobs=12)\n",
    "\n",
    "sgd_clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = sgd_clf.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:amb1] *",
   "language": "python",
   "name": "conda-env-amb1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
